
<p align="center">
  <img src="https://github.com/shammur/PRESUP/blob/main/presup_logo.png" width="350" title="PRESUP">
<!--   <img src="your_relative_path_here_number_2_large_name" width="350" alt="accessibility text"> -->
</p>

# SemEval 2022 Task 3
# Evaluating presuppositional knowledge in language models

<!-- [![Build Status](https://travis-ci.org/joemccann/dillinger.svg?branch=master)](https://travis-ci.org/joemccann/dillinger) -->

## Tasks

PRESUP includes the two following sub-tasks: 
- a binary classification: Predicting the acceptability of sentences (**A** _vs_ **UA**)
<!-- - , which consists in predicting the acceptability label assigned to each sentence of the test set; -->
- a regression task: Predicting the degree of Acceptance in a five Likert-scale
<!-- - , which consists in predicting the average score assigned by human annotators on a five Likert-scale with respect to the subset of data evaluated via crowdsourcing. -->


## Data
The data comprise of sentences in 3 languages:  **English**, **Italian**, and **French**. 

For each sub-task and each language: 
- The dataset will be split into training and test set
- Additionally, a trail data (a small subset of training set) is released to give participants a proper idea of the data and expected formats.


For the **binary-classification** sub-task, the training and test set will be composed by 10,000  and 23,000 samples, respectively;
For the **regression** sub-task, 1,000 sentences will be provided for the training set and 600 for the test set.



## License

MIT

**Free Software, Hell Yeah!**

   [dill]: <https://github.com/joemccann/dillinger>
   [git-repo-url]: <https://github.com/joemccann/dillinger.git>

